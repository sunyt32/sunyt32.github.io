<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Yutao Sun</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/about/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/about/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/about/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/about/">
          <h2 class="nav-title">Yutao Sun</h2>
        </a>
        <ul>
          <li><a href="/about/">About</a></li>
          <li><a href="/about/portfolio/">Portfolio</a></li>
        </ul>
    </div>
  </nav>

    <main>
      <div class="about">
  <div class="profile">
    <img class="selfie" alt="Yutao Sun 孙宇涛" src="assets/img/sunyt.jpg" />
    <div class="info">
      <div class="title">Yutao Sun 孙宇涛</div>
      <div class="description">PhD student in Tsinghua University</div>
    </div>
  </div>

  <div class="content">
    <h1 id="about-me">About Me</h1>
<p>I’m an incoming PhD student in Tsinghua University, advised by <a href="http://dbgroup.cs.tsinghua.edu.cn/wangjy/">Jianyong Wang</a>. Meanwhile, I’m working as a research intern in Microsoft Research Asia, mentored by <a href="http://dong.li/">Li Dong</a>. My research interest is the LLM backbone, long sequence’s modeling and inference, and LLM’s application on other domains.</p>

<p>Email: syt23@mails.tsinghua.edu.cn<br />
Links: [<a href="https://github.com/sunyt32">GitHub</a>] [<a href="https://twitter.com/sunyt_thu">Twitter</a>] [<a href="https://scholar.google.com/citations?user=apGDooYAAAAJ&amp;hl=en">Google Scholar</a>]</p>

<h1 id="education">Education</h1>
<ul>
  <li>Ph.D. student, Tsinghua University (2023/08 ~ )
    <ul>
      <li>Incoming…</li>
    </ul>
  </li>
  <li>Undergrauate student, Tsinghua University (2018/08 ~ 2023/07)
    <ul>
      <li>Computer Science and Technology (2020/08 ~ 2023/07)</li>
      <li>Mathematics and Physics (2018/08 ~ 2020/07)</li>
    </ul>
  </li>
  <li>Taiyuan No.5 Middle School (2015/08 ~ 2018/07)
    <ul>
      <li>Participated in Physics Olympics and achieved nothing</li>
    </ul>
  </li>
</ul>

<h1 id="recent-news">Recent News</h1>
<ul>
  <li>(07/2023) Gave a talk at DAMO Academy about RetNet</li>
  <li>(07/2023) Gave a talk at BAAI about RetNet</li>
</ul>

<h1 id="publications">Publications</h1>

<h2 id="preprint">Preprint</h2>
<ul>
  <li><a href="https://arxiv.org/pdf/2307.08621.pdf"><strong>Retentive Network: A Successor to Transformer for Large Language Models</strong></a><br />
<strong>Yutao Sun</strong>*, Li Dong*, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, Furu Wei.<br />
arXiv:2307.08621, 2023.<br />
[<a href="https://arxiv.org/pdf/2307.08621.pdf">pdf</a>][<a href="https://github.com/microsoft/unilm/tree/master/retnet">code</a>]</li>
  <li><a href="https://arxiv.org/pdf/2212.06713.pdf"><strong>Structured Prompting: Scaling In-Context Learning to 1,000 Examples</strong></a><br />
Yaru Hao*, <strong>Yutao Sun</strong>*, Li Dong, Zhixiong Han, Yuxian Gu, Furu Wei.<br />
arXiv:2212.06713, 2022.<br />
[<a href="https://arxiv.org/pdf/2212.06713.pdf">pdf</a>][<a href="https://github.com/sunyt32/structured-prompting">code</a>]</li>
</ul>

<h2 id="conference">Conference</h2>
<ul>
  <li><a href="https://arxiv.org/pdf/2212.10554.pdf"><strong>A Length-Extrapolatable Transformer</strong></a><br />
<strong>Yutao Sun</strong>, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, Furu Wei.
Association for Computational Linguistics (ACL), Long paper, 2023.<br />
[<a href="https://arxiv.org/pdf/2212.10554.pdf">pdf</a>][<a href="https://github.com/sunyt32/torchscale">code</a>]</li>
  <li><a href="https://arxiv.org/pdf/2212.10559.pdf"><strong>Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</strong></a><br />
Damai Dai, <strong>Yutao Sun</strong>, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, Furu Wei.
Findings of Association for Computational Linguistics (Findings of ACL), Long paper, 2023.<br />
[<a href="https://arxiv.org/pdf/2212.10559.pdf">pdf</a>]</li>
  <li><a href="https://arxiv.org/pdf/2205.10183.pdf"><strong>Prototypical Calibration for Few-shot Learning of Language Models</strong></a><br />
Zhixiong Han, Yaru Hao, Li Dong, <strong>Yutao Sun</strong>, Furu Wei.<br />
International Conference on Learning Representations (ICLR), 2023.<br />
[<a href="https://arxiv.org/pdf/2205.10183.pdf">pdf</a>]</li>
</ul>

<h1 id="honors--awards">Honors &amp; Awards</h1>
<ul>
  <li>(06/2023) Outstanding Graduate &amp; Thesis, Tsinghua University</li>
  <li>(09/2022) Tang Jun-Yuan Scolarship, Tsinghua University</li>
  <li>(09/2020) Academic &amp; Social Work Excellence Award, Tsinghua University</li>
</ul>

<h1 id="teaching-experience">Teaching Experience</h1>
<ul>
  <li>Teaching Assistant in Software Engineering (2022 Spring, 2022 Fall, 2023 Fall)</li>
</ul>

    </br>
    <!-- <div class="social-layer">
      <div class="social-icons">
        <ul>
          
<li>
  <a href="mailto:sunyt32@163.com" title="email">
    <span class="fa-stack fa-lg">
      <i class="fa fa-circle fa-stack-2x"></i>
      <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
    </span>
  </a>
</li>












































        </ul>
      </div>
    </div> -->
  </div>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2023-07-29 15:21:48 +0800">2023</time> Yutao Sun 孙宇涛. <a href="https://github.com/kssim/about-portfolio/">A.P</a> theme by kssim.
      </span>
    </footer>
  </body>
</html>
